Smells:

Username:
Suspected patterns:
1:
<input type=email data-codeception-id=login-email-input name=email>
ancestor data-hypernova-key="login_main_page"
sibling <header class="LoginHeaderWide">
ancestor <section class="LoginPage">
<form class="LoginCreate-loginForm" action=".../account"

5:
<form class="cia-sign-on-form" name="ciaSignOn">
linked label contents: "Email Address"
<input type=email>
<input name="email_CQa3I5u48cEghgJtNSqAMYpoRXZg40H2dgVpOxgMRQjn%2F%2BGnnK65YhkHLdR6kfkJ">
near and below in markup <h1 class="cia-sign-on__heading">Sign In to BestBuy.com</h1>

26:
<input name="username" id="input_username">
ancestor <div class="login_row">
ancestor <div class="loginbox">
ancestor <div class="loginbox_left">
ancestor <div class="loginbox_content">
near and below in markup <h2>Sign in</h2>
<form id="login_form" name="logon">

37:
<input name="loginName" data-auid="loginPage_field_LoginName">
linked label contents: "Login name or email"
<form name="loginForm" action=".../account"
ancestor <div id="checkoutLogin">
ancestor <div class="normal_login">

119:
<input id="username" name="username" for="username" title="Please enter your username">
linked label contents: "Username"
ancestor <div class="cssmod_usernameField_234234">
<form id="loginForm" class="member-login-form">
ancestor <div class="cssmod_memberLogin_sdf987">
ancestor <div class="cssmod_loginWrapper_sjd987 loginWrapper">

Actual patterns observed so far:
KEYWORDS = email, login, sign-on, signOn, username
√ <input name; id; title; or, fairly frequently, other attrs> contains KEYWORDS
√ ancestor classes and IDs (and, rarely, other attrs) contain KEYWORDS
√ <input type=email> Made it worse. Dropped per-tag accuracy from .85 to .83. Got a negative weight. I don't think this is a good smell by itself, because some username fields are meant to take emails, and others aren't. May reintroduce this if we add hidden layers so it can be part of a boolean computation.
<form action="...../account">
<form attrs=KEYWORDS>
linked label contents: KEYWORDS
near and below <hN> containing KEYWORDS

Try with and without one feature per keyword.

254:
Gets the wrong email field: a hidden one from a hidden "subscribe" popup.
Add a smell for visibility.
Maybe break off email as a separate smell, separate from other keywords.

440:
Has a concerningly low confidence, though it succeeds pagewise.

Added ancestor keyword rules.

37:
It's picking some phone number field from inside a hidden "Call us" pulldown. Why isn't it skipping the invisible stuff?
222, 256:
Grabbing the search field for no reason. Login field looks like it should be yummier.

Reverted ancestor keyword rules for now.

isVisible was calling offscreen elements visible. Fixed that. That reduced our universe of input tags. Page accuracy fell from 95% to 90%, puzzlingly. 146 is the new failure, but it doesn't fail in actual Fathom. 452 is the other failure. The correct target node has a tie for first place. I'm going to add 20 more samples so I have more than 1 or 2 failures to inform me and to give us a broader base to decide whether things really improve or hurt results or not.

At 40 samples, I notice that 146 and 187 have no target=true candidates. Let's fix that. Ah, isVisible was wrongly excluding things on 146 that were above the fold. (Don't ask me why it's loading scrolled in only 1 of my browsers.) Fixed it to use absolute coords rather than viewport-relative ones. Removed the tests against things being off the right and bottom of the page for now, because I'm not sure how to test that the window isn't legitimately super-wide or at least scrollable.
Fixing isVisible made 146 and 187 pass.

Next, is there anything obvious up with 395 and 452? If so, fix. If not, get more samples and search for the next signal to implement.

395 is picking an unrelated email subscription field. Trying breaking out email keyword as a separate smell.
Damn!
Suddenly 95→100% on the first 40 samples. Went from a mix of confidences hovering around 50-75% to basically 100% across the board, and all it took was one simple change: having it consider "email"ish keywords as separate features from "login"ish.

Pretty soon, I'm going to need a way of running precomputed coeffs using the CLI trainer.

Validated on 19 samples (see emailSplitWithLoginValidation run). 100% training, 100% validation. Big overfit: best validation loss was actually at step 47. The coeffs still wiggle around more (when I add new samples) than I would expect if I were really closing in on a global fit.

Smells from existing FF autofill (https://searchfox.org/mozilla-central/source/toolkit/components/passwordmgr/LoginManagerContent.jsm#855, in _getFormFields() and callees):
* First, note that it starts from a form and tried to figure out how to fill it. It takes a lot of cues from the user: where is the focus? what were the field names when the login was stored?
* Whether the form is HTTPS *useful*
* Whether there are existing saved logins for it
* It anchors on the pw field and looks backward. It assumes the first text field before the pw field is the username field. *useful*
* Password: looks for <input type=password>. Gives up if it finds >3.
* There are "recipes" blowing around that mask out certain fields by selector, mostly uninteresting: https://searchfox.org/mozilla-central/source/toolkit/components/passwordmgr/content/recipes.json.
  * 9 recipes in all, across username and pw
  * A few have to do with enabling consideration of hidden fields on sites doing purposeful obfuscation.
  * Another dodges confusion with other pw-like forms that happen to be onscreen.
  * Another dodges a site that puts pw and un in separate forms.
  * The rest of for random peculiarities.
* Username: <input type=text|email|url|tel|number> *useful*
* 2 pw fields are identical (in the case of a password-change form).

Add false positives. Make sure that doesn't throw training off. If it does, fix it: add signal or whatever. If it doesn't, see if it throws off validation.
Fixed fathom-trainer to judge negative samples better. Now I'll see how negatives are doing in training and validation and attack those smells.
Next signals:
  * "Create/register" in nearby headings. (On fp44, all the attrs are compiled noise.)
  * First/last name fields in same form.
  * "Create/register/reg" smells (even on ancestors)
  * Maybe "join" smells on submit buttons
Go up 5 parents, do a querySelector for headings, filter out ones that are visually after the input, then check the remainder for smells. When the thing isn't a header, it's often at least got "title" or "head" in its class. Maybe just look for short text nodes with large font size.
